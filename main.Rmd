---
title: "main"
author: "Farhan"
date: "2022-11-26"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r required}
if (!require("pacman")) install.packages("pacman")
pacman::p_load(twitteR, wordcloud, tm, tidyr, tidytext, syuzhet, ngram, NLP, RColorBrewer, RTextTools, e1071, caret, knitr)
```

```{r library}
library(shiny)
library(here)
library(vroom)
library(dplyr)
library(ggplot2)
library(plotly)
library(syuzhet)
library(twitteR)
library(ROAuth)
library(tm)
library(rtweet)
library(wordcloud)
```

```{r}
twitter<- vroom(here("cleandata.csv"))
tweet<- twitter$text

ui <- fluidPage(
    titlePanel("SENTIMENT ANALISIS THE BRITISH MUSEUM in TWITTER"),
        mainPanel(
            
            tabsetPanel(type = "tabs",
                        tabPanel("List Cuitan tentang British Museum", DT::dataTableOutput('tbl')),
                        tabPanel("Sentiment", plotOutput("sentiment")), 
                        tabPanel("Wordcloud", plotOutput("Wordcloud")),
                        tabPanel("Frekuensi Cuitan", plotOutput("frekuensi")) 
                        )
        )
    )
server <- function(input, output) {
    
    #///Output Data
    output$tbl = DT::renderDataTable({
        DT::datatable(twitter, options = list(lengthChange = FALSE))
    })
    
    
    #///Output sentiment
    output$sentiment <- renderPlot({sentiment_dataset<-read.csv("cleandata.csv",stringsAsFactors = FALSE)

    review <-as.character(sentiment_dataset$text)

    get_nrc_sentiment('happy')
    get_nrc_sentiment('excitement')
    s<-get_nrc_sentiment(review)

    review_combine<-cbind(sentiment_dataset$text,s)
    par(mar=rep(3,4))
    barplot(colSums(s),col=rainbow(10),ylab='count',main='Sentiment Score For british museum')
    }, height=400)
    
    #///Output Wordcloud
    output$Wordcloud <- renderPlot({cloud<-readRDS('rawdata.rds')
    clouddf=twListToDF(cloud)
    
    #cleaning data
    #hanya ambil tweet saja
    komen<-clouddf$text
    komenc<-Corpus(VectorSource(komen))
    
    #hapus tanda baca, link url, huruf aneh, dan emoji
    removeURL <-function(x) gsub("http[^[:space:]]*", "", x)
    twitclean <-tm_map(komenc,removeURL)
    
    removeRT<-function(y) gsub("RT", "", y)
    twitclean<-tm_map(twitclean,removeRT)
    
    removeUN<-function(z) gsub("@\\w+", "", z)
    twitclean<-tm_map(twitclean,removeUN)
    
    remove.all <- function(xy) gsub("[^[:alpha:][:space:]]*", "", xy)
    twitclean <- tm_map(twitclean,remove.all)
    
    twitclean<-tm_map(twitclean, removePunctuation)
    clouddf<-tm_map(twitclean, tolower)
    
    
    #membuat nilai untuk masing-masing kata
    {
      dtm<-TermDocumentMatrix(clouddf)
      m<-as.matrix(dtm)
      v<-sort(rowSums(m),decreasing = TRUE)
      cloudval<-data.frame(word=names(v),freq=v)
    }
    
    set.seed(1234) # for reproducibility 
    wordcloud(words = cloudval$word, 
          freq = cloudval$freq, 
          min.freq = 1,           
          max.words =200, 
          random.order=FALSE, 
          rot.per=0.35,            
          colors=brewer.pal(8, "Dark2"))
    
  })
    
    #///Output frekuensi
    output$frekuensi <- renderPlot({rdsdata<-readRDS('rawdata.rds')
    dfdata=twListToDF(rdsdata)
    
    ##visualisasi time series 
    ts_plot(dfdata, "24 hour") +
      ggplot2::theme_minimal() +
      ggplot2::theme(plot.title = ggplot2::element_text(face = "bold")) +
      ggplot2::labs(
        x = NULL, y = NULL,
        title = "Frekuensi cuitan twitter tentang The British Museum selama 5 hari kebelakang",
        subtitle = "Cuitan twitter yang ada mention british museum dalam interval 1 hari",
        caption = "\nSource: Data collected from Twitter's REST API via rtweet"
      )
    }, height=500)
}
shinyApp(ui = ui, server = server)
```



